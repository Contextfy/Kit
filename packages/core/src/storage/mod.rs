use crate::parser::ParsedDoc;
use anyhow::Result;
// use lancedb::connect;
// use arrow::array::{StringArray, StringBuilder};
// use arrow::datatypes::{DataType, Field, Schema as ArrowSchema};
// use arrow::record_batch::RecordBatch;
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::Path;
use uuid::Uuid;

/// çŸ¥è¯†åº“ä¸­çš„ä¸€æ¡è®°å½•
///
/// # å­—æ®µ
///
/// * `id` - è®°å½•çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼ˆUUIDï¼‰
/// * `title` - è®°å½•æ ‡é¢˜ï¼ˆå¯¹äºåˆ‡ç‰‡æ–‡æ¡£ï¼Œè¿™æ˜¯ H2 æ ‡é¢˜ï¼‰
/// * `summary` - å†…å®¹æ‘˜è¦ï¼ˆå‰ 200 ä¸ªå­—ç¬¦ï¼‰
/// * `content` - å®Œæ•´å†…å®¹
/// * `source_path` - åŸå§‹æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè¿½æº¯æºæ–‡ä»¶
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KnowledgeRecord {
    pub id: String,
    pub title: String,
    pub summary: String,
    pub content: String,
    pub source_path: String, // æ–°å¢å­—æ®µï¼šè®°å½•åŸå§‹æ–‡ä»¶è·¯å¾„
}

pub struct KnowledgeStore {
    data_dir: String,
}

impl KnowledgeStore {
    pub fn new(data_dir: &str) -> Result<Self> {
        fs::create_dir_all(data_dir)?;
        Ok(KnowledgeStore {
            data_dir: data_dir.to_string(),
        })
    }

    pub async fn search(&self, query: &str) -> Result<Vec<KnowledgeRecord>> {
        let mut records = Vec::new();

        for entry in fs::read_dir(&self.data_dir)? {
            let entry = entry?;
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) == Some("json") {
                let content = fs::read_to_string(&path)?;
                if let Ok(record) = serde_json::from_str::<KnowledgeRecord>(&content) {
                    if record.title.to_lowercase().contains(&query.to_lowercase())
                        || record
                            .summary
                            .to_lowercase()
                            .contains(&query.to_lowercase())
                    {
                        records.push(record);
                    }
                }
            }
        }

        Ok(records)
    }

    pub async fn get(&self, id: &str) -> Result<Option<KnowledgeRecord>> {
        for entry in fs::read_dir(&self.data_dir)? {
            let entry = entry?;
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) == Some("json") {
                let content = fs::read_to_string(&path)?;
                if let Ok(record) = serde_json::from_str::<KnowledgeRecord>(&content) {
                    if record.id == id {
                        return Ok(Some(record));
                    }
                }
            }
        }

        Ok(None)
    }

    pub async fn add(&self, doc: &ParsedDoc) -> Result<Vec<String>> {
        let mut ids = Vec::new();

        if doc.sections.is_empty() {
            // å›é€€é€»è¾‘ï¼šå¦‚æœæ–‡æ¡£æ²¡æœ‰åˆ‡ç‰‡ï¼Œå°†æ•´ä¸ªæ–‡æ¡£ä½œä¸ºå•æ¡è®°å½•å­˜å‚¨
            // è¿™ç§æƒ…å†µå¯èƒ½å‡ºç°åœ¨ï¼š
            // 1. æ–‡æ¡£æ²¡æœ‰ H2 æ ‡é¢˜
            // 2. æ—§ç‰ˆæœ¬è§£æçš„æ–‡æ¡£ï¼ˆå‘åå…¼å®¹ï¼‰
            let id = Uuid::new_v4().to_string();
            let record = KnowledgeRecord {
                id: id.clone(),
                title: doc.title.clone(),
                summary: doc.summary.clone(),
                content: doc.content.clone(),
                source_path: doc.path.clone(),
            };

            let json = serde_json::to_string_pretty(&record)?;
            fs::write(Path::new(&self.data_dir).join(format!("{}.json", id)), json)?;
            ids.push(id);
        } else {
            // æ–°é€»è¾‘ï¼šä¸ºæ¯ä¸ªåˆ‡ç‰‡åˆ›å»ºç‹¬ç«‹çš„è®°å½•
            // è¿™æ ·å¯ä»¥å®ç°ç»†ç²’åº¦çš„æ£€ç´¢ï¼Œæå‡æœç´¢ç²¾åº¦
            for slice in &doc.sections {
                let id = Uuid::new_v4().to_string();

                // æ€§èƒ½è€ƒè™‘ï¼šSlicedSection å·²ç»æ‹¥æœ‰æ‰€æœ‰æƒï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨å³å¯
                //
                // ä¸ºä»€ä¹ˆ ParsedDoc ä½¿ç”¨æ‹¥æœ‰æ‰€æœ‰æƒçš„ SlicedSectionï¼Ÿ
                // - ç®€åŒ–ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼šParsedDoc æ— éœ€ç”Ÿå‘½å‘¨æœŸå‚æ•°
                // - é¿å…"è¿”å›å±€éƒ¨å˜é‡å€Ÿç”¨"çš„é—®é¢˜
                // - åœ¨å­˜å‚¨å±‚ï¼ˆJSON åºåˆ—åŒ–ï¼‰é›¶æ‹·è´ä¼˜åŠ¿æ— æ³•ä½“ç°
                //
                // TODO(ä¼˜åŒ–): å½“å‰ä¸ºæ¯ä¸ªåˆ‡ç‰‡åˆ†é…æ–°çš„ String å¯¹è±¡
                // å¦‚æœæ€§èƒ½åˆ†ææ˜¾ç¤ºæ‰¹é‡ç´¢å¼•æ—¶è¿™é‡Œæ˜¯ç“¶é¢ˆï¼Œå¯ä»¥è€ƒè™‘ï¼š
                // 1. ä½¿ç”¨ Cow<'a, str> åœ¨ KnowledgeRecord ä¸­å®ç°é›¶æ‹·è´
                // 2. å»¶è¿Ÿåºåˆ—åŒ–ï¼Œå…ˆåœ¨å†…å­˜ä¸­ç´¯ç§¯è®°å½•
                // 3. ä½¿ç”¨æµå¼ JSON åºåˆ—åŒ–å™¨é¿å…ä¸­é—´ç¼“å†²åŒº
                //
                // æƒè¡¡ï¼šå†…å­˜åˆ†é…å¼€é”€ vs ä»£ç å¤æ‚åº¦
                // å½“å‰é€‰æ‹©ï¼šä¼˜å…ˆä»£ç ç®€æ´æ€§ï¼Œç‰ºç‰²ä¸€å®šçš„æ€§èƒ½

                let record = KnowledgeRecord {
                    id: id.clone(),
                    title: slice.section_title.clone(),
                    summary: slice.content.chars().take(200).collect::<String>(),
                    content: slice.content.clone(), // SlicedSection æ‹¥æœ‰æ‰€æœ‰æƒï¼Œç›´æ¥å…‹éš†
                    source_path: doc.path.clone(),
                };

                let json = serde_json::to_string_pretty(&record)?;
                fs::write(Path::new(&self.data_dir).join(format!("{}.json", id)), json)?;
                ids.push(id);
            }
        }

        Ok(ids) // è¿”å›æ‰€æœ‰åˆ‡ç‰‡çš„ IDï¼ˆå¦‚æœæœ‰åˆ‡ç‰‡ï¼‰æˆ–å•ä¸ªæ–‡æ¡£ ID
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::SlicedSection;
    use std::fs;

    /// åŸºæœ¬åˆ‡ç‰‡å­˜å‚¨æµ‹è¯•
    #[tokio::test]
    async fn test_add_sliced_doc() {
        // åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
        let temp_dir = tempfile::tempdir().unwrap();
        let store = KnowledgeStore::new(temp_dir.path().to_str().unwrap()).unwrap();

        // æ‰‹åŠ¨æ„é€ åŒ…å« 2 ä¸ªåˆ‡ç‰‡çš„ ParsedDoc
        let doc = ParsedDoc {
            path: "/fake/path.md".to_string(),
            title: "Test Doc".to_string(),
            summary: "Test summary".to_string(),
            content: "Full content".to_string(),
            sections: vec![
                SlicedSection {
                    section_title: "Section 1".to_string(),
                    content: "Content 1".to_string(),
                    parent_doc_title: "Test Doc".to_string(),
                },
                SlicedSection {
                    section_title: "Section 2".to_string(),
                    content: "Content 2".to_string(),
                    parent_doc_title: "Test Doc".to_string(),
                },
            ],
        };

        // è°ƒç”¨ add()
        let ids = store.add(&doc).await.unwrap();

        // æ–­è¨€ï¼šè¿”å› 2 ä¸ª ID
        assert_eq!(ids.len(), 2);

        // æ–­è¨€ï¼šå­˜å‚¨ç›®å½•ä¸­æœ‰ 2 ä¸ª JSON æ–‡ä»¶
        let json_files: Vec<_> = fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(|e| e.ok())
            .filter(|e| e.path().extension().and_then(|s| s.to_str()) == Some("json"))
            .collect();
        assert_eq!(json_files.len(), 2);

        // æ–­è¨€ï¼šæ¯ä¸ªè®°å½•éƒ½æœ‰æ­£ç¡®çš„ source_path
        for json_file in json_files {
            let content = fs::read_to_string(json_file.path()).unwrap();
            let record: KnowledgeRecord = serde_json::from_str(&content).unwrap();
            assert_eq!(record.source_path, "/fake/path.md");
        }
    }

    /// ç©ºåˆ‡ç‰‡å›é€€æµ‹è¯•
    #[tokio::test]
    async fn test_add_empty_sections() {
        // åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
        let temp_dir = tempfile::tempdir().unwrap();
        let store = KnowledgeStore::new(temp_dir.path().to_str().unwrap()).unwrap();

        // æ„é€ æ²¡æœ‰åˆ‡ç‰‡çš„ ParsedDocï¼ˆå›é€€é€»è¾‘ï¼‰
        let doc = ParsedDoc {
            path: "/legacy/doc.md".to_string(),
            title: "Legacy Doc".to_string(),
            summary: "Legacy summary".to_string(),
            content: "Full legacy content".to_string(),
            sections: vec![], // ç©ºåˆ‡ç‰‡ï¼Œè§¦å‘å›é€€é€»è¾‘
        };

        // è°ƒç”¨ add()
        let ids = store.add(&doc).await.unwrap();

        // æ–­è¨€ï¼šè¿”å› 1 ä¸ª IDï¼ˆæ•´ç¯‡æ–‡æ¡£ä½œä¸ºå•æ¡è®°å½•ï¼‰
        assert_eq!(ids.len(), 1);

        // æ–­è¨€ï¼šå­˜å‚¨ç›®å½•ä¸­æœ‰ 1 ä¸ª JSON æ–‡ä»¶
        let json_files: Vec<_> = fs::read_dir(temp_dir.path())
            .unwrap()
            .filter_map(|e| e.ok())
            .filter(|e| e.path().extension().and_then(|s| s.to_str()) == Some("json"))
            .collect();
        assert_eq!(json_files.len(), 1);

        // æ–­è¨€ï¼šè®°å½•çš„ title æ˜¯æ–‡æ¡£æ ‡é¢˜ï¼ˆè€Œéåˆ‡ç‰‡æ ‡é¢˜ï¼‰
        let content = fs::read_to_string(json_files[0].path()).unwrap();
        let record: KnowledgeRecord = serde_json::from_str(&content).unwrap();
        assert_eq!(record.title, "Legacy Doc");
        assert_eq!(record.source_path, "/legacy/doc.md");
    }

    /// é²æ£’æ€§æµ‹è¯•ï¼ˆæç«¯æƒ…å†µï¼‰
    #[tokio::test]
    async fn test_storage_robustness() {
        let temp_dir = tempfile::tempdir().unwrap();
        let store = KnowledgeStore::new(temp_dir.path().to_str().unwrap()).unwrap();

        // æ„é€ æç«¯æ•°æ®
        let mut sections = vec![
            // Case A: æ ‡é¢˜ä¸ºç©ºï¼Œå†…å®¹åŒ…å« Emoji å’Œç‰¹æ®Šç¬¦å·
            SlicedSection {
                section_title: "".to_string(),
                content: "ğŸš€ Emoji & \"Quotes\" & \nNewlines".to_string(),
                parent_doc_title: "Edge Case Doc".to_string(),
            },
            // Case B: åªæœ‰æ ‡é¢˜ï¼Œå†…å®¹ä¸ºç©º
            SlicedSection {
                section_title: "Empty Content".to_string(),
                content: "".to_string(),
                parent_doc_title: "Edge Case Doc".to_string(),
            },
        ];

        // Case C: å¤§é‡åˆ‡ç‰‡ (æ¨¡æ‹Ÿé•¿æ–‡) - å¾ªç¯ç”Ÿæˆ 50 ä¸ªåˆ‡ç‰‡
        for i in 0..50 {
            sections.push(SlicedSection {
                section_title: format!("Section {}", i),
                content: format!("Content for section {}", i),
                parent_doc_title: "Edge Case Doc".to_string(),
            });
        }

        let doc = ParsedDoc {
            path: "C:\\Windows\\System32\\weird_path.md".to_string(), // Windows è·¯å¾„åæ–œæ æµ‹è¯•
            title: "Edge Case Doc".to_string(),
            summary: "".to_string(),
            content: "".to_string(),
            sections,
        };

        // éªŒè¯æ˜¯å¦èƒ½æˆåŠŸå†™å…¥ï¼Œä¸ Panic
        let ids = store.add(&doc).await.unwrap();

        // éªŒè¯ Case C: ç¡®ä¿ç”Ÿæˆçš„ ID æ•°é‡æ­£ç¡® (2ä¸ªæ‰‹åŠ¨ + 50ä¸ªå¾ªç¯ = 52)
        assert_eq!(ids.len(), 52);

        // éªŒè¯ JSON è¯»å–å›æ¥çš„æ•°æ®å®Œæ•´æ€§ (ç¡®ä¿ç‰¹æ®Šå­—ç¬¦æ²¡æœ‰ä¹±ç )
        // è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œååºåˆ—åŒ–ï¼Œæ–­è¨€ content == "ğŸš€ Emoji & \"Quotes\" & \nNewlines"
        let first_record = store.get(&ids[0]).await.unwrap().unwrap();
        assert_eq!(first_record.content, "ğŸš€ Emoji & \"Quotes\" & \nNewlines");
        assert_eq!(
            first_record.source_path,
            "C:\\Windows\\System32\\weird_path.md"
        );

        // éªŒè¯ Case B: ç©ºå†…å®¹åˆ‡ç‰‡ä¹Ÿèƒ½æ­£ç¡®å­˜å‚¨
        let second_record = store.get(&ids[1]).await.unwrap().unwrap();
        assert_eq!(second_record.title, "Empty Content");
        assert_eq!(second_record.content, "");

        // éªŒè¯ Case C: æ‰€æœ‰ ID éƒ½æ˜¯å”¯ä¸€çš„ï¼ˆé€šè¿‡é›†åˆå»é‡åæ•°é‡ä¸å˜ï¼‰
        let unique_ids: std::collections::HashSet<_> = ids.iter().collect();
        assert_eq!(unique_ids.len(), 52);
    }
}
