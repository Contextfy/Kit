use anyhow::Result;
use pulldown_cmark::{Event, HeadingLevel, Parser, Tag};
use std::fs;
use std::path::Path;

/// æ™ºèƒ½æå–å†…å®¹æ‘˜è¦
///
/// æå–å†…å®¹çš„æ‘˜è¦
///
/// æå–é€»è¾‘ï¼š
/// 1. å¦‚æœä»¥ä»£ç å—å¼€å§‹ï¼ˆ```ï¼‰ï¼ŒåŒ…å«æ•´ä¸ªä»£ç å—
/// 2. æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒæ¢è¡Œç¬¦ï¼ˆ\n\nï¼‰ä½œä¸ºæ®µè½åˆ†éš”
/// 3. ç¡¬æˆªæ–­ä¿æŠ¤ï¼šè¶…è¿‡ 1000 å­—ç¬¦å¼ºåˆ¶æˆªæ–­
/// 4. å›é€€ï¼šæ— æ®µè½åˆ†éš”æ—¶æˆªå–å‰ 200 å­—ç¬¦
/// 5. æ¸…ç†é¦–å°¾ç©ºç™½
///
/// # æ€§èƒ½ä¼˜åŒ–
///
/// å¦‚æœè°ƒç”¨è€…ç¡®ä¿ä¼ å…¥**å·² trim çš„å†…å®¹**ï¼Œå¯ä»¥è·³è¿‡å†…éƒ¨ trimï¼Œæå‡æ€§èƒ½ã€‚
/// å‡½æ•°ä¼šè‡ªåŠ¨æ£€æµ‹æ˜¯å¦éœ€è¦ trimï¼Œåªåœ¨å¿…è¦æ—¶æ‰æ‰§è¡Œã€‚
///
/// # å‚æ•°
///
/// - `content`: å†…å®¹å­—ç¬¦ä¸²ï¼ˆå»ºè®®å·² trim ä»¥è·å¾—æœ€ä½³æ€§èƒ½ï¼‰
///
/// # è¿”å›
///
/// æå–çš„æ‘˜è¦å­—ç¬¦ä¸²
pub fn extract_summary(content: &str) -> String {
    const MAX_SUMMARY_CHARS: usize = 1000;
    const FALLBACK_CHARS: usize = 200;

    // æ€§èƒ½ä¼˜åŒ–ï¼šåªåœ¨éœ€è¦æ—¶æ‰ trimï¼ˆé¿å…ä¸å¿…è¦çš„éå†ï¼‰
    // å¦‚æœå†…å®¹é¦–å°¾æœ‰ç©ºç™½å­—ç¬¦ï¼Œæ‰æ‰§è¡Œ trimï¼›å¦åˆ™ç›´æ¥ä½¿ç”¨åŸå†…å®¹
    let content = if content.starts_with(|c: char| c.is_whitespace())
        || content.ends_with(|c: char| c.is_whitespace())
    {
        content.trim()
    } else {
        content
    };

    if content.is_empty() {
        return String::new();
    }

    // æ£€æŸ¥æ˜¯å¦ä»¥ä»£ç å—å¼€å§‹
    // ç”±äºå·²æ‰§è¡Œï¼ˆæˆ–ç¡®è®¤ä¸éœ€è¦ï¼‰trimï¼Œå¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ starts_with() æ£€æµ‹
    let in_code_block = content.starts_with("```");

    // æŸ¥æ‰¾åˆé€‚çš„æˆªæ–­ç‚¹
    let end_pos = if in_code_block {
        // å¦‚æœåœ¨ä»£ç å—ä¸­ï¼Œæ‰¾åˆ°ä»£ç å—ç»“æŸæ ‡è®°
        find_code_block_end(content)
    } else {
        // å¦åˆ™æŸ¥æ‰¾ç¬¬ä¸€ä¸ª \n\n
        content.find("\n\n")
    };

    // æå–å†…å®¹
    let extracted = match end_pos {
        Some(pos) => &content[..pos],
        None => content,
    };

    // ç¡¬æˆªæ–­ä¿æŠ¤
    let truncated = if extracted.chars().count() > MAX_SUMMARY_CHARS {
        smart_truncate(extracted, MAX_SUMMARY_CHARS)
    } else if extracted.chars().count() > FALLBACK_CHARS && end_pos.is_none() {
        // å›é€€æœºåˆ¶ï¼šæ— æ®µè½åˆ†éš”ä¸”è¶…è¿‡ 200 å­—ç¬¦ï¼Œæˆªå–å‰ 200 å­—ç¬¦
        smart_truncate(extracted, FALLBACK_CHARS)
    } else {
        extracted.to_string()
    };

    truncated.trim().to_string()
}

/// æŸ¥æ‰¾ä»£ç å—ç»“æŸä½ç½®
///
/// æ‰«æå†…å®¹ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå…³é—­çš„ ``` æ ‡è®°
/// è¿”å›ä»£ç å—ç»“æŸåçš„ä½ç½®ï¼ˆåŒ…å« ``` æ ‡è®°æœ¬èº«ï¼‰
///
/// # è¿”å›å€¼
///
/// è¿”å›**å­—èŠ‚åç§»é‡** (byte offset)ï¼Œè€Œéå­—ç¬¦ç´¢å¼•
/// è¿™æ ·å¯ä»¥å®‰å…¨åœ°ç”¨äºå­—ç¬¦ä¸²åˆ‡ç‰‡æ“ä½œ
fn find_code_block_end(content: &str) -> Option<usize> {
    let bytes = content.as_bytes();
    let mut i = 0;
    let len = bytes.len();

    // è·³è¿‡å¼€å§‹çš„ ```
    while i < len {
        if bytes[i] == b'`' {
            let backtick_count = count_backticks_bytes(&bytes[i..]);
            if backtick_count >= 3 {
                i += backtick_count;
                break;
            }
        }
        i += 1;
    }

    // æŸ¥æ‰¾å…³é—­çš„ ```
    while i < len {
        if bytes[i] == b'`' {
            let backtick_count = count_backticks_bytes(&bytes[i..]);
            if backtick_count >= 3 {
                return Some(i + backtick_count);
            }
        }
        i += 1;
    }

    None
}

/// è®¡ç®—è¿ç»­çš„åå¼•å·æ•°é‡ï¼ˆåŸºäºå­—èŠ‚ï¼‰
///
/// # å‚æ•°
///
/// * `bytes` - å­—èŠ‚åˆ‡ç‰‡
///
/// # è¿”å›å€¼
///
/// è¿”å›è¿ç»­åå¼•å·çš„æ•°é‡
fn count_backticks_bytes(bytes: &[u8]) -> usize {
    bytes.iter().take_while(|&&b| b == b'`').count()
}

/// æ™ºèƒ½æˆªæ–­ï¼šåœ¨æœ€åä¸€ä¸ªå¥å­ç»“æŸç¬¦å¤„æˆªæ–­
///
/// å¦‚æœèƒ½åœ¨é™åˆ¶å†…æ‰¾åˆ°å¥å­ç»“æŸç¬¦ï¼ˆ. ! ?ï¼‰ï¼Œåœ¨æ­¤å¤„æˆªæ–­
/// å¦åˆ™åœ¨é™åˆ¶å¤„æˆªæ–­å¹¶æ·»åŠ  ...
fn smart_truncate(text: &str, max_chars: usize) -> String {
    let chars: Vec<char> = text.chars().collect();
    let limit = max_chars.min(chars.len());

    // ä»é™åˆ¶ä½ç½®å‘å‰æŸ¥æ‰¾æœ€åä¸€ä¸ªå¥å­ç»“æŸç¬¦
    let mut sentence_end = None;
    for i in (0..limit).rev() {
        if chars[i] == '.' || chars[i] == '!' || chars[i] == '?' {
            // ç¡®ä¿å¥å­ç»“æŸç¬¦åé¢æ˜¯ç©ºæ ¼æˆ–æ¢è¡Œ
            if i + 1 < chars.len() && (chars[i + 1].is_whitespace() || i + 1 == limit) {
                sentence_end = Some(i + 1);
                break;
            }
        }
    }

    match sentence_end {
        Some(pos) => chars[..pos].iter().collect(),
        None => {
            // æ‰¾ä¸åˆ°å¥å­ç»“æŸç¬¦ï¼Œåœ¨é™åˆ¶å¤„æˆªæ–­
            let truncated: String = chars[..limit].iter().collect();
            // æ·»åŠ çœç•¥å·ï¼ˆå¦‚æœæ–‡æœ¬è¢«æˆªæ–­äº†ï¼‰
            if limit < chars.len() {
                format!("{}...", truncated.trim_end())
            } else {
                truncated
            }
        }
    }
}

/// è§£æåçš„ Markdown æ–‡æ¡£
///
/// # å­—æ®µ
///
/// * `path` - åŸå§‹æ–‡ä»¶è·¯å¾„
/// * `title` - æ–‡æ¡£æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ H1 æ ‡é¢˜æˆ–æ–‡ä»¶åï¼‰
/// * `summary` - æ–‡æ¡£æ‘˜è¦ï¼ˆæ™ºèƒ½æå–é¦–æ®µæˆ–ä»£ç å—ï¼Œæœ€å¤š 1000 å­—ç¬¦ï¼‰
/// * `content` - å®Œæ•´çš„ Markdown å†…å®¹
/// * `sections` - æŒ‰ H2 æ ‡é¢˜åˆ‡ç‰‡çš„ç‰‡æ®µåˆ—è¡¨ï¼ˆæ‹¥æœ‰æ‰€æœ‰æƒï¼‰
///
/// # æ‰€æœ‰æƒè®¾è®¡
///
/// ä¸ºäº†ç®€åŒ–ç”Ÿå‘½å‘¨æœŸç®¡ç†å¹¶é¿å…å¤æ‚çš„å€Ÿç”¨å…³ç³»ï¼Œ
/// `ParsedDoc` ä¸­çš„ `sections` æ‹¥æœ‰æ•°æ®çš„æ‰€æœ‰æƒï¼ˆè€Œéå€Ÿç”¨ï¼‰ã€‚
///
/// æƒè¡¡ï¼š
/// - âŒ å¤±å»é›¶æ‹·è´ä¼˜åŠ¿ï¼ˆéœ€è¦å¤åˆ¶åˆ‡ç‰‡æ•°æ®ï¼‰
/// - âœ… ç®€åŒ– API å’Œç”Ÿå‘½å‘¨æœŸï¼ˆParsedDoc æ— éœ€ç”Ÿå‘½å‘¨æœŸå‚æ•°ï¼‰
/// - âœ… æ›´å®¹æ˜“åºåˆ—åŒ–å’Œå­˜å‚¨ï¼ˆè™½ç„¶ ParsedDoc æœ¬èº«ä¸åºåˆ—åŒ–ï¼‰
///
/// è¿™ä¸ªé€‰æ‹©æ˜¯åŸºäºå®ç”¨ä¸»ä¹‰çš„è€ƒè™‘ï¼šåœ¨å­˜å‚¨å±‚ï¼ˆJSON åºåˆ—åŒ–ï¼‰é›¶æ‹·è´ä¼˜åŠ¿æ— æ³•ä½“ç°ã€‚
#[derive(Debug, Clone)]
pub struct ParsedDoc {
    pub path: String,
    pub title: String,
    pub summary: String,
    pub content: String,
    pub sections: Vec<SlicedSection>, // æ‹¥æœ‰æ‰€æœ‰æƒçš„åˆ‡ç‰‡
}

/// æ‹¥æœ‰æ‰€æœ‰æƒçš„æ–‡æ¡£åˆ‡ç‰‡ï¼ˆç”¨äº ParsedDocï¼‰
///
/// ä¸ `SlicedDoc<'a>` ä¸åŒï¼Œè¿™ä¸ªç»“æ„ä½“æ‹¥æœ‰æ‰€æœ‰æ•°æ®çš„æ‰€æœ‰æƒï¼Œ
/// ä¸éœ€è¦ç”Ÿå‘½å‘¨æœŸå‚æ•°ã€‚
#[derive(Debug, Clone)]
pub struct SlicedSection {
    pub section_title: String,
    pub content: String,
    pub parent_doc_title: String,
    pub summary: String,
}

/// è¡¨ç¤ºä¸€ä¸ªæŒ‰ H2 æ ‡é¢˜åˆ‡ç‰‡åçš„æ–‡æ¡£ç‰‡æ®µï¼ˆé›¶æ‹·è´ç‰ˆæœ¬ï¼‰
///
/// # å­—æ®µ
///
/// * `section_title` - H2 æ ‡é¢˜æ–‡æœ¬ï¼ˆæ‹¥æœ‰æ‰€æœ‰æƒï¼‰
/// * `content` - è¯¥ H2 ä¸‹çš„å®Œæ•´å†…å®¹ï¼ˆ**ä¸åŒ…å« H2 æ ‡é¢˜æœ¬èº«**ï¼Œä»æ ‡é¢˜ä¹‹ååˆ°ä¸‹ä¸€ä¸ª H2 ä¹‹å‰ï¼Œå€Ÿç”¨åˆ‡ç‰‡ï¼‰
/// * `parent_doc_title` - çˆ¶æ–‡æ¡£çš„ H1 æ ‡é¢˜ï¼ˆå€Ÿç”¨åˆ‡ç‰‡ï¼‰
/// * `summary` - åˆ‡ç‰‡æ‘˜è¦ï¼ˆæ™ºèƒ½æå–é¦–æ®µæˆ–ä»£ç å—ï¼Œæ‹¥æœ‰æ‰€æœ‰æƒï¼‰
///
/// # é›¶æ‹·è´è®¾è®¡
///
/// `content` å’Œ `parent_doc_title` ä½¿ç”¨å€Ÿç”¨åˆ‡ç‰‡ï¼Œé¿å…å¤åˆ¶æ•°æ®ã€‚
/// `section_title` å’Œ `summary` æ‹¥æœ‰æ‰€æœ‰æƒï¼Œå› ä¸ºå®ƒä»¬éœ€è¦ä»è§£æçš„å¤šä¸ªäº‹ä»¶ä¸­æ‹¼æ¥æˆ–è®¡ç®—ã€‚
///
/// # æ–¹æ¡ˆ D ä¼˜åŒ–
///
/// åˆ©ç”¨ pulldown-cmark AST ç‰¹æ€§ï¼Œåˆ‡ç‰‡ä» `Event::End(Heading).range.end` å¼€å§‹ï¼Œ
/// å› æ­¤ `content` å­—æ®µ**ä¸åŒ…å« H2 æ ‡é¢˜æœ¬èº«**ï¼ˆå¦‚ `## Title`ï¼‰ã€‚
///
/// ä¼˜åŠ¿ï¼š
/// - é¿å… Header Pollutionï¼ˆæ ‡é¢˜æ±¡æŸ“æ‘˜è¦ï¼‰
/// - èŠ‚çœ Token å¼€æ”¯ï¼ˆå­˜å‚¨å’Œ Embedding ä¸é‡å¤æ ‡é¢˜ï¼‰
/// - æ•°æ®ç»“æ„æ›´æ¸…æ™°ï¼ˆæ ‡é¢˜åœ¨ `section_title`ï¼Œå†…å®¹åœ¨ `content`ï¼‰
#[derive(Debug, Clone)]
pub struct SlicedDoc<'a> {
    pub section_title: String,
    pub content: &'a str,
    pub parent_doc_title: &'a str,
    pub summary: String,
}

pub fn parse_markdown(file_path: &str) -> Result<ParsedDoc> {
    if !Path::new(file_path).exists() {
        anyhow::bail!("File not found: {}", file_path);
    }

    let content = fs::read_to_string(file_path)?;
    let parser = Parser::new(&content);

    let mut title = String::new();
    let mut in_h1 = false;

    for event in parser {
        match event {
            Event::Start(pulldown_cmark::Tag::Heading(HeadingLevel::H1, ..)) => {
                in_h1 = true;
            }
            Event::End(pulldown_cmark::Tag::Heading(HeadingLevel::H1, ..)) => {
                in_h1 = false;
            }
            Event::Text(text) if in_h1 && title.is_empty() => {
                title = text.to_string();
            }
            _ => {}
        }
    }

    if title.is_empty() {
        title = Path::new(file_path)
            .file_stem()
            .and_then(|s| s.to_str())
            .unwrap_or("Untitled")
            .to_string();
    }

    // æ€§èƒ½ä¼˜åŒ–ï¼šå…ˆ trimï¼Œå†è°ƒç”¨ extract_summaryï¼Œé¿å…é‡å¤ trim
    // è¿™æ ·å¯ä»¥ç¡®ä¿ extract_summary æ¥æ”¶çš„æ˜¯å·²æ¸…ç†çš„å†…å®¹ï¼Œå†…éƒ¨æ— éœ€å†æ¬¡ trim
    let content_cleaned = content.trim().to_string();
    let summary = extract_summary(&content_cleaned);

    // è°ƒç”¨é›¶æ‹·è´åˆ‡ç‰‡å‡½æ•°ï¼Œç„¶åå°†ç»“æœè½¬æ¢ä¸ºæ‹¥æœ‰æ‰€æœ‰æƒçš„ç‰ˆæœ¬
    // æ€§èƒ½è€ƒè™‘ï¼šè¿™é‡Œéœ€è¦å¤åˆ¶æ•°æ®ï¼Œä½†æƒè¡¡æ˜¯ç®€åŒ–äº†ç”Ÿå‘½å‘¨æœŸç®¡ç†
    let zero_copy_slices = slice_by_headers(&content_cleaned, &title);
    let sections: Vec<SlicedSection> = zero_copy_slices
        .into_iter()
        .map(|slice| SlicedSection {
            section_title: slice.section_title,
            content: slice.content.to_string(), // å€Ÿç”¨ â†’ æ‹¥æœ‰æ‰€æœ‰æƒ
            parent_doc_title: slice.parent_doc_title.to_string(),
            summary: slice.summary, // å·²ç»æ‹¥æœ‰æ‰€æœ‰æƒï¼Œç›´æ¥ç§»åŠ¨
        })
        .collect();

    Ok(ParsedDoc {
        path: file_path.to_string(),
        title,
        summary,
        content: content_cleaned,
        sections,
    })
}

/// æ ¹æ® H2 æ ‡é¢˜å°† Markdown å†…å®¹åˆ‡ç‰‡ä¸ºå¤šä¸ªç‰‡æ®µ
///
/// # å‚æ•°
///
/// * `content` - è¦åˆ‡ç‰‡çš„ Markdown å†…å®¹
/// * `parent_title` - çˆ¶æ–‡æ¡£çš„æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯ H1ï¼‰
///
/// # è¿”å›å€¼
///
/// è¿”å›ä¸€ä¸ª `SlicedDoc` å‘é‡ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ª H2 æ ‡é¢˜åŠå…¶å†…å®¹ã€‚
/// å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ H2 æ ‡é¢˜ï¼Œåˆ™è¿”å›ç©ºå‘é‡ã€‚
///
/// # è¡Œä¸º
///
/// - å¿½ç•¥ç¬¬ä¸€ä¸ª H2 æ ‡é¢˜ä¹‹å‰çš„æ‰€æœ‰å†…å®¹
/// - H3/H4 ç­‰å­æ ‡é¢˜ä½œä¸ºå½“å‰ H2 ç‰‡æ®µçš„å†…å®¹çš„ä¸€éƒ¨åˆ†
/// - ä½¿ç”¨ AST è§£æï¼Œä»£ç å—ä¸­çš„ `##` ä¸ä¼šè¢«è¯¯è®¤ä¸º H2 æ ‡é¢˜
/// - é›¶æ‹·è´å®ç°ï¼š`content` å’Œ `parent_doc_title` ä½¿ç”¨å€Ÿç”¨åˆ‡ç‰‡
/// - **æ–¹æ¡ˆ D ä¼˜åŒ–**ï¼šåˆ‡ç‰‡ä» `Event::End(Heading).range.end` å¼€å§‹ï¼Œ**ä¸åŒ…å« H2 æ ‡é¢˜æœ¬èº«**
/// - ç©ºåˆ‡ç‰‡ï¼ˆæ ‡é¢˜åæ— å†…å®¹ï¼‰ä¼šè¢«è‡ªåŠ¨è·³è¿‡
///
/// # æ–¹æ¡ˆ D çš„ä¼˜åŠ¿
///
/// - é¿å… Header Pollutionï¼šåˆ‡ç‰‡å†…å®¹ä¸å«æ ‡é¢˜ï¼Œæ‘˜è¦æå–æ›´å‡†ç¡®
/// - èŠ‚çœ Token å¼€æ”¯ï¼šæ ‡é¢˜å·²å­˜å‚¨åœ¨ `section_title`ï¼Œæ— éœ€åœ¨ `content` ä¸­é‡å¤
/// - æ•°æ®ç»“æ„æ¸…æ™°ï¼šæ ‡é¢˜ä¸å†…å®¹åˆ†ç¦»
///
/// # ç¤ºä¾‹
///
/// ```ignore
/// let content = "# Doc\n\n## Section 1\nContent 1\n\n## Section 2\nContent 2";
/// let slices = slice_by_headers(content, "Doc");
/// assert_eq!(slices.len(), 2);
/// assert_eq!(slices[0].section_title, "Section 1");
/// assert!(!slices[0].content.contains("## Section 1")); // åˆ‡ç‰‡ä¸åŒ…å«æ ‡é¢˜
/// assert!(slices[0].content.contains("Content 1"));       // åªåŒ…å«å®é™…å†…å®¹
/// ```
pub fn slice_by_headers<'a>(content: &'a str, parent_title: &'a str) -> Vec<SlicedDoc<'a>> {
    let mut slices = Vec::new();

    let parser = Parser::new(content);
    let mut h2_start_indices: Vec<usize> = Vec::new(); // å­˜å‚¨ H2 æ ‡é¢˜å¼€å§‹ä½ç½®
    let mut h2_end_indices: Vec<usize> = Vec::new();
    let mut h2_titles: Vec<String> = Vec::new();
    let mut current_h2_title: Option<String> = None;

    // ç¬¬ä¸€ééå†ï¼šæ”¶é›†æ‰€æœ‰ H2 æ ‡é¢˜çš„ç»“æŸä½ç½®å’Œæ–‡æœ¬
    // åˆ©ç”¨ AST ç‰¹æ€§ï¼šä½¿ç”¨ Event::End(Heading).range.end ä½œä¸ºåˆ‡ç‰‡èµ·ç‚¹
    // è¿™æ ·åˆ‡ç‰‡å†…å®¹ä¸åŒ…å« H2 æ ‡é¢˜æœ¬èº«ï¼Œé¿å… Header Pollution
    for (event, range) in parser.into_offset_iter() {
        match event {
            Event::Start(Tag::Heading(HeadingLevel::H2, ..)) => {
                // è®°å½• H2 æ ‡é¢˜çš„å¼€å§‹ä½ç½®ï¼ˆç”¨äºè®¡ç®—åˆ‡ç‰‡ç»“æŸè¾¹ç•Œï¼‰
                h2_start_indices.push(range.start);
                current_h2_title = Some(String::new());
            }
            Event::End(Tag::Heading(HeadingLevel::H2, ..)) => {
                // å®‰å…¨ä¿®å¤ï¼šä¿è¯ h2_titles å’Œ h2_end_indices é•¿åº¦ä¸€è‡´
                // å³ä½¿æ ‡é¢˜ä¸ºç©ºï¼Œä¹Ÿæ·»åŠ å ä½ç¬¦ï¼Œé¿å…æ•°ç»„ç´¢å¼•é”™ä½
                let title = current_h2_title.take().unwrap_or_default();
                h2_titles.push(title);
                // å…³é”®æ”¹åŠ¨ï¼šå­˜å‚¨ range.endï¼ˆæ ‡é¢˜ç»“æŸä½ç½®ï¼‰
                // è¿™æ ·åˆ‡ç‰‡ä»æ ‡é¢˜ä¹‹åå¼€å§‹ï¼Œä¸åŒ…å«æ ‡é¢˜æœ¬èº«
                h2_end_indices.push(range.end);
            }
            Event::Text(text) | Event::Code(text) => {
                // å¤„ç†æ–‡æœ¬å’Œè¡Œå†…ä»£ç 
                if let Some(title) = &mut current_h2_title {
                    title.push_str(&text);
                }
            }
            Event::SoftBreak | Event::HardBreak => {
                // å¤„ç†æ¢è¡Œï¼Œè½¬æ¢ä¸ºç©ºæ ¼
                if let Some(title) = &mut current_h2_title {
                    title.push(' ');
                }
            }
            _ => {}
        }
    }

    // å¦‚æœæ²¡æœ‰ H2 æ ‡é¢˜ï¼Œè¿”å›ç©ºå‘é‡
    if h2_end_indices.is_empty() {
        return slices;
    }

    // ç¬¬äºŒé˜¶æ®µï¼šæ ¹æ® H2 ç»“æŸä½ç½®è¿›è¡Œåˆ‡ç‰‡
    for (i, &end_idx) in h2_end_indices.iter().enumerate() {
        // è®¡ç®—åˆ‡ç‰‡çš„ç»“æŸä½ç½®
        // å…³é”®ä¿®å¤ï¼šä½¿ç”¨ h2_start_indices[i + 1] è€Œä¸æ˜¯ h2_end_indices[i + 1]
        // h2_end_indices å­˜å‚¨çš„æ˜¯æ ‡é¢˜ç»“æŸä½ç½®ï¼Œä½¿ç”¨ä¸‹ä¸€ä¸ª H2 çš„ç»“æŸä½ç½®ä¼šå¯¼è‡´å½“å‰åˆ‡ç‰‡åŒ…å«ä¸‹ä¸€ä¸ª H2 æ ‡é¢˜
        // æ­£ç¡®åšæ³•æ˜¯ä½¿ç”¨ä¸‹ä¸€ä¸ª H2 çš„å¼€å§‹ä½ç½®ï¼Œç¡®ä¿åˆ‡ç‰‡åœ¨ä¸‹ä¸€ä¸ª H2 æ ‡é¢˜ä¹‹å‰ç»“æŸ
        let slice_end = if i + 1 < h2_start_indices.len() {
            h2_start_indices[i + 1]
        } else {
            content.len()
        };

        // è·³è¿‡æ ‡é¢˜åçš„æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ˆæ¢è¡Œã€ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰ï¼Œæ‰¾åˆ°å®é™…å†…å®¹çš„èµ·å§‹ä½ç½®
        let after_title = &content[end_idx..];
        let content_start = skip_leading_whitespace(after_title);

        // è®¡ç®—å®é™…å†…å®¹çš„èµ·å§‹åç§»é‡
        let skipped_bytes = after_title.len() - content_start.len();
        let start_byte_offset = end_idx + skipped_bytes;

        // æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºåˆ‡ç‰‡ï¼šä½¿ç”¨ç²¾ç¡®çš„è¾¹ç•Œè®¡ç®—
        // slice_end å·²ç»é€šè¿‡ h2_start_indices[i+1] ç²¾ç¡®ç•Œå®š
        // å¦‚æœ start_byte_offset >= slice_endï¼Œè¯´æ˜æ²¡æœ‰å®é™…å†…å®¹
        let is_empty = start_byte_offset >= slice_end;

        if is_empty {
            continue;
        }

        let slice_content = &content[start_byte_offset..slice_end];

        // æ€§èƒ½ä¼˜åŒ–ï¼ˆæ–¹æ¡ˆDï¼‰ï¼šåª trim ä¸€æ¬¡ï¼Œå¤ç”¨ç»“æœ
        // 1. æ£€æŸ¥æ˜¯å¦ä¸ºç©ºåˆ‡ç‰‡ï¼ˆå®‰å…¨ä¿®å¤ï¼‰
        // 2. ä¼ å…¥ extract_summaryï¼Œé¿å…å†…éƒ¨å†æ¬¡ trim
        let slice_content_trimmed = slice_content.trim();

        // å®‰å…¨ä¿®å¤ï¼šè·³è¿‡ç©ºåˆ‡ç‰‡ï¼ˆåªæœ‰ç©ºç™½å­—ç¬¦çš„å†…å®¹ï¼‰
        if slice_content_trimmed.is_empty() {
            continue;
        }

        let mut section_title = h2_titles.get(i).cloned().unwrap_or_default();

        // æ™ºèƒ½æ ‡é¢˜ç”Ÿæˆï¼šå¦‚æœæ ‡é¢˜ä¸ºç©ºï¼Œä»å†…å®¹è‡ªåŠ¨ç”Ÿæˆæœ‰æ„ä¹‰çš„æ ‡é¢˜
        // è¿™é¿å…äº†æ•°æ®ä¸¢å¤±ï¼ŒåŒæ—¶ä¿æŒæ ‡é¢˜çš„å¯è¯»æ€§
        if section_title.is_empty() {
            section_title = generate_smart_title(slice_content_trimmed);
        }

        // æ€§èƒ½ä¼˜åŒ–ï¼šä¼ å…¥å·² trim çš„å†…å®¹ï¼Œé¿å… extract_summary å†…éƒ¨é‡å¤ trim
        let summary = extract_summary(slice_content_trimmed);

        slices.push(SlicedDoc {
            section_title,
            content: slice_content,
            parent_doc_title: parent_title,
            summary,
        });
    }

    slices
}

/// ä»åˆ‡ç‰‡å†…å®¹ç”Ÿæˆæ™ºèƒ½æ ‡é¢˜
///
/// å½“ H2 æ ‡é¢˜ä¸ºç©ºæ—¶ï¼Œä»å†…å®¹çš„å‰å‡ ä¸ªå­—ç¬¦ç”Ÿæˆæœ‰æ„ä¹‰çš„æ ‡é¢˜ã€‚
///
/// # é€»è¾‘
/// 1. æå–å†…å®¹çš„å‰å‡ ä¸ªè¯ï¼ˆæœ€å¤š 30 ä¸ªå­—ç¬¦ï¼‰
/// 2. æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¥å­ç»“æŸç¬¦ï¼ˆã€‚ï¼ï¼ï¼Ÿ.!?ï¼‰ä½œä¸ºæˆªæ–­ç‚¹
/// 3. å¦‚æœæ˜¯ä»£ç å—å¼€å¤´ï¼Œä½¿ç”¨ "Code: ..." å‰ç¼€
/// 4. æ¸…ç†ç©ºç™½å’Œæ¢è¡Œ
/// 5. å¦‚æœå¤ªé•¿ï¼Œæ·»åŠ çœç•¥å·
///
/// # å‚æ•°
/// - `content`: åˆ‡ç‰‡å†…å®¹ï¼ˆåº”è¯¥å·² trimï¼‰
///
/// # è¿”å›
/// ç”Ÿæˆçš„æ™ºèƒ½æ ‡é¢˜ï¼ˆå¦‚æœå†…å®¹ä¸ºç©ºï¼Œè¿”å› "Untitled Section"ï¼‰
fn generate_smart_title(content: &str) -> String {
    const MAX_TITLE_CHARS: usize = 30;

    if content.is_empty() {
        return "Untitled Section".to_string();
    }

    // æ£€æŸ¥æ˜¯å¦ä»¥ä»£ç å—å¼€å§‹
    let is_code_block = content.starts_with("```");

    // æå–å‰å‡ ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜åŸºç¡€
    let content_start = if is_code_block {
        // å¯¹äºä»£ç å—ï¼Œè·³è¿‡ ``` åæå–
        let after_backticks = &content[3..];
        let first_line = after_backticks.lines().next().unwrap_or("");
        format!("Code: {}", first_line.trim())
    } else {
        // æå–ç¬¬ä¸€è¡Œæˆ–å‰ MAX_TITLE_CHARS ä¸ªå­—ç¬¦
        let first_line = content.lines().next().unwrap_or("");
        if first_line.chars().count() > MAX_TITLE_CHARS {
            // å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
            find_sentence_break(first_line, MAX_TITLE_CHARS)
        } else {
            first_line.to_string()
        }
    };

    // æ¸…ç†æ ‡é¢˜
    let title = content_start
        .trim()
        .replace('\n', " ")
        .split_whitespace()
        .collect::<Vec<_>>()
        .join(" ");

    // å¦‚æœä»ç„¶å¤ªé•¿ï¼Œå¼ºåˆ¶æˆªæ–­
    if title.chars().count() > MAX_TITLE_CHARS {
        let truncated: String = title.chars().take(MAX_TITLE_CHARS - 3).collect();
        format!("{}...", truncated)
    } else {
        title
    }
}

/// åœ¨å¥å­ç»“æŸç¬¦å¤„æˆªæ–­æ–‡æœ¬
///
/// æŸ¥æ‰¾æœ€åä¸€ä¸ªå¥å­ç»“æŸç¬¦ï¼ˆã€‚ï¼ï¼ï¼Ÿ.!?ï¼‰å¹¶åœ¨æ­¤å¤„æˆªæ–­
fn find_sentence_break(text: &str, max_chars: usize) -> String {
    let chars: Vec<char> = text.chars().collect();
    let limit = max_chars.min(chars.len());

    // ä»é™åˆ¶ä½ç½®å‘å‰æŸ¥æ‰¾æœ€åä¸€ä¸ªå¥å­ç»“æŸç¬¦
    for i in (0..limit).rev() {
        let c = chars[i];
        if c == 'ã€‚' || c == 'ï¼' || c == 'ï¼Ÿ' || c == '.' || c == '!' || c == '?' {
            return chars[..=i].iter().collect();
        }
    }

    // æ²¡æ‰¾åˆ°å¥å­ç»“æŸç¬¦ï¼Œåœ¨é™åˆ¶å¤„æˆªæ–­
    let truncated: String = chars[..limit].iter().collect();
    format!("{}...", truncated.trim_end())
}

/// è·³è¿‡å­—ç¬¦ä¸²å¼€å¤´çš„æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ˆæ¢è¡Œã€ç©ºæ ¼ã€åˆ¶è¡¨ç¬¦ç­‰ï¼‰
///
/// ç”¨äºå»é™¤åˆ‡ç‰‡æ ‡é¢˜åå¯èƒ½å­˜åœ¨çš„ç©ºè¡Œå’Œç©ºç™½
///
/// # ç¤ºä¾‹
/// - `"\n\nContent"` â†’ `"Content"`
/// - `"  \t\nContent"` â†’ `"Content"`
/// - `"\n"` â†’ `""`
/// - `"  \t  "` â†’ `""`
fn skip_leading_whitespace(s: &str) -> &str {
    s.trim_start_matches(|c: char| c.is_whitespace())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_with_h1() {
        let result = parse_markdown("test_data/sample_with_h1.md");
        assert!(result.is_ok());
        let doc = result.unwrap();
        assert_eq!(doc.title, "Test Document");
    }

    #[test]
    fn test_parse_without_h1() {
        let result = parse_markdown("test_data/sample_without_h1.md");
        assert!(result.is_ok());
        let doc = result.unwrap();
        assert_eq!(doc.title, "sample_without_h1");
    }

    // Summary extraction tests
    #[test]
    fn test_extract_summary_normal_paragraph() {
        let content = "è¿™æ˜¯ç¬¬ä¸€æ®µã€‚\n\nè¿™æ˜¯ç¬¬äºŒæ®µ...";
        let summary = extract_summary(content);
        assert_eq!(summary, "è¿™æ˜¯ç¬¬ä¸€æ®µã€‚");
    }

    #[test]
    fn test_extract_summary_with_code_block() {
        let content = "```rust\npub fn foo() -> Bar\n```\n\nä¸€äº›è¯´æ˜æ–‡å­—...";
        let summary = extract_summary(content);
        assert!(summary.contains("```rust"));
        assert!(summary.contains("pub fn foo() -> Bar"));
        assert!(summary.contains("```"));
    }

    #[test]
    fn test_extract_summary_code_block_with_newlines() {
        let content = "```rust\npub fn foo(\n    x: i32\n) -> Bar\n```\n\nè¯´æ˜";
        let summary = extract_summary(content);
        // åº”è¯¥åŒ…å«å®Œæ•´çš„ä»£ç å—ï¼Œå³ä½¿å†…éƒ¨æœ‰æ¢è¡Œ
        assert!(summary.contains("```rust"));
        assert!(summary.contains("pub fn foo("));
        assert!(summary.contains(") -> Bar"));
        assert!(summary.contains("```"));
    }

    #[test]
    fn test_extract_summary_no_paragraph_break() {
        let content = "çŸ­æ–‡æœ¬æˆ–æ²¡æœ‰åŒæ¢è¡Œçš„é•¿æ–‡æœ¬...";
        let summary = extract_summary(content);
        // åº”è¯¥è¿”å›åŸå†…å®¹ï¼ˆçŸ­äº 200 å­—ç¬¦ï¼‰
        assert_eq!(summary, content);
    }

    #[test]
    fn test_extract_summary_long_without_break() {
        let content = "a".repeat(300);
        let summary = extract_summary(&content);
        // åº”è¯¥æˆªæ–­åˆ° 200 å­—ç¬¦å·¦å³
        assert!(summary.len() <= 203); // 200 + "..."
        assert!(summary.ends_with("..."));
    }

    #[test]
    fn test_extract_summary_wall_of_text() {
        let content = "è¿™æ˜¯ä¸€ä¸ªè¶…é•¿çš„æ®µè½ï¼Œç”¨æˆ·ä»ä¸æ¢è¡Œã€‚".repeat(100);
        let summary = extract_summary(&content);
        // åº”è¯¥æˆªæ–­åˆ° 1000 å­—ç¬¦å·¦å³
        assert!(summary.chars().count() <= 1003);
        assert!(summary.ends_with("..."));
    }

    #[test]
    fn test_extract_summary_empty_content() {
        let summary = extract_summary("");
        assert_eq!(summary, "");
    }

    #[test]
    fn test_extract_summary_whitespace_only() {
        let summary = extract_summary("   \n\n   ");
        assert_eq!(summary, "");
    }

    #[test]
    fn test_extract_summary_sentence_truncation() {
        let content = "è¿™æ˜¯ç¬¬ä¸€å¥è¯ã€‚è¿™æ˜¯ç¬¬äºŒå¥è¯ã€‚è¿™æ˜¯ç¬¬ä¸‰å¥è¯ã€‚è¿™æ˜¯ç¬¬å››å¥è¯ã€‚".repeat(10);
        let summary = extract_summary(&content);
        // åº”è¯¥åœ¨å¥å­ç»“æŸå¤„æˆªæ–­
        assert!(summary.chars().count() <= 1003);
        // æ£€æŸ¥æ˜¯å¦åœ¨å¥å­è¾¹ç•Œæˆªæ–­ï¼ˆä»¥ . ! ? ç»“å°¾ï¼‰
        let last_char = summary.chars().last().unwrap();
        if summary.ends_with("...") {
            // å¦‚æœæ·»åŠ äº† ...ï¼Œå‰é¢çš„å†…å®¹å¯èƒ½ä¸åœ¨å¥å­è¾¹ç•Œ
            assert!(summary.chars().count() <= 1003);
        } else {
            assert!(last_char == '.' || last_char == '!' || last_char == '?');
        }
    }

    // Slicing tests
    #[test]
    fn test_slice_standard_three_h2() {
        let content = r#"# Parent Doc

Some preamble text.

## Section One

Content for section one.

## Section Two

Content for section two.

## Section Three

Content for section three.
"#;

        let slices = slice_by_headers(content, "Parent Doc");
        assert_eq!(slices.len(), 3);
        assert_eq!(slices[0].section_title, "Section One");
        assert_eq!(slices[1].section_title, "Section Two");
        assert_eq!(slices[2].section_title, "Section Three");

        // å…³é”®éªŒè¯ï¼šåˆ‡ç‰‡å†…å®¹ä¸åŒ…å« H2 æ ‡é¢˜ï¼ˆæ–¹æ¡ˆ D çš„æ ¸å¿ƒæ”¹è¿›ï¼‰
        assert!(!slices[0].content.contains("## Section One"));
        assert!(!slices[1].content.contains("## Section Two"));
        assert!(!slices[2].content.contains("## Section Three"));

        // åˆ‡ç‰‡å†…å®¹åº”è¯¥åªåŒ…å«å®é™…å†…å®¹
        assert!(slices[0].content.contains("Content for section one."));
        assert!(slices[1].content.contains("Content for section two."));
        assert!(slices[2].content.contains("Content for section three."));
    }

    #[test]
    fn test_slice_no_headers() {
        let content = r#"# Parent Doc

Just some content without any H2 headers.
"#;

        let slices = slice_by_headers(content, "Parent Doc");
        assert_eq!(slices.len(), 0);
    }

    #[test]
    fn test_slice_nested_h3() {
        let content = r#"# Parent Doc

## Main Section

Some content.

### Subsection A

Subsection content.

### Subsection B

More subsection content.

End of main section.
"#;

        let slices = slice_by_headers(content, "Parent Doc");
        assert_eq!(slices.len(), 1);
        assert_eq!(slices[0].section_title, "Main Section");
        // H3 åº”è¯¥åŒ…å«åœ¨åˆ‡ç‰‡å†…å®¹ä¸­
        assert!(slices[0].content.contains("### Subsection A"));
        assert!(slices[0].content.contains("Subsection content."));
        assert!(slices[0].content.contains("### Subsection B"));
    }

    #[test]
    fn test_slice_code_block_trap() {
        let content = "# Parent Doc\n\n## Section One\n\nRegular content.\n\n```\nThis is a code block.\nIt contains ## which should NOT be a header.\nEnd of code.\n```\n\nMore content.\n";

        let slices = slice_by_headers(content, "Parent Doc");
        assert_eq!(slices.len(), 1);
        assert_eq!(slices[0].section_title, "Section One");

        // æ–¹æ¡ˆ Dï¼šåˆ‡ç‰‡å†…å®¹ä¸åŒ…å« H2 æ ‡é¢˜
        assert!(!slices[0].content.contains("## Section One"));

        // ä»£ç å—åº”è¯¥å®Œæ•´åŒ…å«åœ¨åˆ‡ç‰‡ä¸­
        assert!(slices[0].content.contains("```"));
        assert!(slices[0]
            .content
            .contains("## which should NOT be a header"));
    }

    #[test]
    fn test_slice_empty_content_between_headers() {
        let content = r#"# Parent Doc

## Section One

## Section Two

Some content.
"#;

        let slices = slice_by_headers(content, "Parent Doc");

        // æ–¹æ¡ˆ Dï¼šç©ºåˆ‡ç‰‡è¢«è·³è¿‡ï¼ˆSection One åé¢ç›´æ¥æ˜¯ Section Twoï¼Œæ²¡æœ‰å®é™…å†…å®¹ï¼‰
        assert_eq!(slices.len(), 1);
        assert_eq!(slices[0].section_title, "Section Two");
        assert!(slices[0].content.contains("Some content."));
    }

    #[test]
    fn test_slice_unicode_and_emoji() {
        let content = r#"# çˆ¶æ–‡æ¡£

## ç®€ä»‹ ğŸš€

è¿™æ˜¯ä¸€ä¸ªåŒ…å«ä¸­æ–‡å’Œ Emoji çš„æµ‹è¯•ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ç‰¹æ€§ä¸€
- ç‰¹æ€§äºŒ âœ¨
"#;

        let slices = slice_by_headers(content, "çˆ¶æ–‡æ¡£");
        assert_eq!(slices.len(), 2);
        assert_eq!(slices[0].section_title, "ç®€ä»‹ ğŸš€");
        assert_eq!(slices[1].section_title, "åŠŸèƒ½ç‰¹æ€§");
        assert!(slices[0].content.contains("ä¸­æ–‡å’Œ Emoji"));
        assert!(slices[1].content.contains("âœ¨"));
    }

    #[test]
    fn test_slice_inline_formatting() {
        let content = "# Parent Doc\n\n## Section **One**\n\nContent for section one.\n\n## Section *Two*\n\nContent for section two.\n";

        let slices = slice_by_headers(content, "Parent Doc");
        assert_eq!(slices.len(), 2);
        // åº”è¯¥åŒ…å«å®Œæ•´çš„å†…è”æ ¼å¼
        assert_eq!(slices[0].section_title, "Section One");
        assert_eq!(slices[1].section_title, "Section Two");
        assert!(slices[0].content.contains("Content for section one"));
        assert!(slices[1].content.contains("Content for section two"));
    }
}

#[test]
fn test_edge_cases_empty_h2() {
    // æµ‹è¯•ç©ºçš„ H2 æ ‡é¢˜
    let content = "# Parent\n\n##\n\nContent after empty header.";
    let slices = slice_by_headers(content, "Parent");

    // æ™ºèƒ½æ ‡é¢˜ç”Ÿæˆï¼šç©ºæ ‡é¢˜ä¼šä»å†…å®¹ç”Ÿæˆæœ‰æ„ä¹‰çš„æ ‡é¢˜
    // é¿å…æ•°æ®ä¸¢å¤±ï¼Œä¿æŒå†…å®¹å¯æœç´¢
    assert_eq!(
        slices.len(),
        1,
        "Empty H2 titles should generate smart titles from content"
    );

    // éªŒè¯æ™ºèƒ½æ ‡é¢˜åŒ…å«å†…å®¹çš„å‰å‡ ä¸ªè¯
    assert!(
        slices[0].section_title.contains("Content after"),
        "Smart title should be generated from content"
    );

    // éªŒè¯å†…å®¹è¢«ä¿ç•™
    assert!(
        slices[0].content.contains("Content after empty header"),
        "Content should be preserved"
    );
}

#[test]
fn test_edge_cases_h2_at_eof() {
    // æµ‹è¯• H2 åé¢ç›´æ¥ EOFï¼ˆæ²¡æœ‰å†…å®¹ï¼‰
    let content = "# Parent\n\n## Section One";
    let slices = slice_by_headers(content, "Parent");

    // æ–¹æ¡ˆ Dï¼šç©ºåˆ‡ç‰‡è¢«è·³è¿‡
    assert_eq!(slices.len(), 0);
}

#[test]
fn test_edge_cases_consecutive_h2() {
    // æµ‹è¯•è¿ç»­çš„ H2ï¼ˆä¸­é—´æ²¡æœ‰å†…å®¹ï¼‰
    let content = "# Parent\n\n## First\n## Second\n## Third\n\nContent.";
    let slices = slice_by_headers(content, "Parent");

    // æ–¹æ¡ˆ Dï¼šåªæœ‰åŒ…å«å®é™…å†…å®¹çš„åˆ‡ç‰‡ä¼šè¢«ä¿ç•™
    // First å’Œ Second åé¢ç›´æ¥æ˜¯ä¸‹ä¸€ä¸ªæ ‡é¢˜ï¼Œæ‰€ä»¥è¢«è·³è¿‡
    // Third åé¢æœ‰ "Content."ï¼Œæ‰€ä»¥è¢«ä¿ç•™
    assert_eq!(slices.len(), 1);
    assert_eq!(slices[0].section_title, "Third");
    assert!(slices[0].content.contains("Content."));
}
